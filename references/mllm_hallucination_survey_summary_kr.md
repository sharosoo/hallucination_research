# 멀티모달 대규모 언어모델의 환각 현상: 종합 서베이

> **원문:** Bai et al., "Hallucination of Multimodal Large Language Models: A Survey", arXiv:2404.18930v2, April 2025

---

## 1. 문제 정의 (Problem Definition)

### 1.1 환각(Hallucination)이란?

**멀티모달 대규모 언어모델(MLLM)의 환각**은 생성된 텍스트 응답이 제공된 시각적 콘텐츠와 일치하지 않는 현상을 말합니다.

```
예시:
입력 이미지: 공원에서 사람들이 서있는 사진
MLLM 응답: "분홍색 꽃이 피어있고, 벤치와 울타리가 있으며, 구름이 보입니다"
문제: 이미지에 분홍색 꽃, 벤치, 울타리, 구름이 없음 → 환각!
```

### 1.2 환각의 세 가지 유형

| 유형 | 설명 | 예시 |
|------|------|------|
| **카테고리 환각** | 이미지에 없는 객체를 언급 | "벤치와 울타리가 있다" (실제로 없음) |
| **속성 환각** | 객체는 맞지만 속성이 틀림 | "분홍색 꽃" (실제론 흰색) |
| **관계 환각** | 객체 간 관계가 틀림 | "사람들이 그녀 주변에 서서 지켜보고 있다" (실제론 아님) |

### 1.3 LLM vs MLLM 환각의 차이

- **LLM 환각**: 생성된 콘텐츠와 검증 가능한 실세계 사실 간의 불일치
- **MLLM 환각**: 생성된 텍스트와 **제공된 시각적 콘텐츠** 간의 불일치 (교차 모달 비일관성)

---

## 2. 환각의 원인 (Hallucination Causes)

### 2.1 데이터 관련 원인

#### 2.1.1 데이터 양 (Quantity)
- MLLM 학습 데이터는 LLM의 텍스트 전용 데이터보다 훨씬 적음
- 부족한 데이터 → 문제적 교차 모달 정렬 → 환각 발생

#### 2.1.2 데이터 품질 (Quality)
| 문제 유형 | 설명 |
|----------|------|
| **노이즈 데이터** | 웹에서 수집한 이미지-텍스트 쌍에 부정확하거나 잘못 정렬된 데이터 포함 |
| **다양성 부족** | 긍정 지시만 있고 부정 지시("No"라고 답해야 하는 경우)가 부족 |
| **상세 설명 수준** | 너무 상세하거나 너무 간략한 설명 모두 문제 (열린 문제) |

#### 2.1.3 통계적 편향 (Statistical Bias)
- **빈번한 객체**: "사람"이 가장 자주 등장 → 없어도 예측하는 경향
- **객체 동시 출현**: 냉장고 → 전자레인지가 같이 나올 것으로 예측 (실제 없어도)

### 2.2 모델 관련 원인

#### 2.2.1 약한 비전 모델
- 시각 개념의 오분류 또는 잘못된 해석
- 인코딩 과정에서의 정보 손실

#### 2.2.2 언어 모델 사전 지식 (Language Prior)
```
예시:
이미지: 빨간 바나나 (비정상적)
MLLM: "노란 바나나" (LLM의 사전 지식이 시각 정보를 덮어씀)
```
- 언어 모델이 비전 모델보다 훨씬 큼 → 언어 기반 정보를 우선시하는 경향

#### 2.2.3 약한 정렬 인터페이스
- 교차 모달 인터페이스(Q-Former, Linear Projection)의 한계
- 시각적 특징과 언어 임베딩 간의 분포 격차

### 2.3 학습 관련 원인

- **시퀀스 수준 감독 부재**: 토큰 레벨 최적화만 수행
- **시각적 감독 부족**: 이미지의 복잡한 공간 구조 학습 어려움
- **RLHF 부재**: LLM과 달리 MLLM 학습에서 인간 피드백 강화학습 단계 누락

### 2.4 추론 관련 원인

#### 2.4.1 시각적 주의력 결핍 (Visual Attention Deficiency)
```
문제:
생성이 진행될수록 self-attention이 이전 텍스트 토큰에 집중
→ 시각 콘텐츠에 대한 주의력 희석
→ 출력이 이미지와 무관해짐
```

#### 2.4.2 함정 시각 토큰 (Trap Visual Tokens)
- 일부 이미지 토큰이 과도한 주의를 받음
- 중요한 세부 정보를 담은 토큰은 낮은 주의 가중치 → 환각 유발

---

## 3. 평가 지표 및 벤치마크 (Metrics and Benchmarks)

### 3.1 주요 평가 지표

#### CHAIR (Caption Hallucination Assessment with Image Relevance)
```python
CHAIR_i = |{환각된 객체}| / |{언급된 모든 객체}|  # 인스턴스 기준
CHAIR_s = |{환각된 객체가 있는 문장}| / |{모든 문장}|  # 문장 기준
```

#### POPE (Polling-based Object Probing Evaluation)
- "이미지에 자동차가 있나요?"와 같은 Yes/No 질문으로 변환
- 무작위(Random), 인기(Popular), 적대적(Adversarial) 샘플링 전략

#### LLM 기반 평가
- GPT-4를 사용한 응답 분석 및 점수 매기기
- GAVIE, HaELM, FaithScore 등

### 3.2 주요 벤치마크

| 벤치마크 | 크기 | 작업 유형 | 평가 대상 |
|----------|------|----------|----------|
| POPE | 3,000 | 판별 | 카테고리 환각 |
| MME | 1,457 | 판별 | 존재, 개수, 위치, 색상 |
| MMHal-Bench | 96 | 생성 | 속성, 관계, 개수 등 |
| AMBER | 15,202 | 판별+생성 | 카테고리, 속성, 관계 |
| HallusionBench | 1,129 | 생성 | 모델 진단 (시각 의존/보충) |
| FaithScore | 2,000 | 생성 | 세분화된 환각 유형 |

---

## 4. 환각 완화 방법 (Hallucination Mitigation)

### 4.1 데이터 기반 완화

#### 4.1.1 부정 데이터 (Negative Data)
**LRV-Instruction**: 긍정 + 부정 지시 포함
- 존재하지 않는 객체에 대한 질문
- "No"라고 답해야 하는 경우 학습

#### 4.1.2 반사실 데이터 (Counterfactual Data)
**HalluciDoctor**: 
- 다중 MLLM 교차 검증으로 환각 탐지
- 반사실 시각 지시 생성으로 데이터 균형화

#### 4.1.3 추론 데이터 (Reasoning Data)
**REVERIE**: 
- 응답이 왜 맞는지/틀린지 근거(rationale) 포함
- 반사적 지시 튜닝

#### 4.1.4 클린 데이터 (Clean Data)
**EOS Decision**: 
- MLLM의 인지 한계를 초과하는 상세 데이터 필터링
- 적시에 생성 종료하도록 학습

### 4.2 모델 기반 완화

#### 4.2.1 해상도 확대
```
CLIP-ViT-L-224 → CLIP-ViT-L-336 → 성능 향상, 환각 감소
```

#### 4.2.2 다양한 비전 인코더
- CLIP + DINO 특징 혼합
- 추가 도구 모델 (객체 탐지, OCR) 통합

#### 4.2.3 전용 모듈
**HallE-Switch**: 파라메트릭 지식의 정도를 제어하는 스위치 모듈

### 4.3 학습 기반 완화

#### 4.3.1 보조 감독
- **시각적 감독**: 마스크 예측 손실 추가
- **대조 학습**: HACL - 환각 텍스트를 하드 네거티브로 사용
- **위치 정렬**: CCA - RoPE 장기 감쇠 영향 완화

#### 4.3.2 강화 학습

| 방법 | 설명 |
|------|------|
| **자동 지표 기반** | NLI, BERTScore 등을 보상으로 사용 (MOCHa) |
| **RLAIF** | AI 피드백 기반 - GPT-4V로 선호도 평가 (HA-DPO, POVID) |
| **RLHF** | 인간 피드백 기반 - 세그먼트 레벨 교정 (RLHF-V) |
| **시각 생성 피드백** | T2I 모델로 캡션에서 이미지 재생성, 불일치 피드백 (ESREAL) |

### 4.4 추론 기반 완화

#### 4.4.1 대조 디코딩 (Contrastive Decoding)
**VCD (Visual Contrastive Decoding)**:
```
원리:
1. 원본 이미지로 분포 생성
2. 왜곡된 이미지로 "편향된" 분포 생성
3. 두 분포를 대조하여 편향 억제
```

#### 4.4.2 가이드 디코딩
- **MARINE**: 객체 탐지 결과로 디코딩 안내
- **GCD**: CLIP 점수로 환각 문장 구분
- **HALC**: 토큰별 최적 시각 컨텍스트 식별

#### 4.4.3 시각적 증폭
- **M3ID**: 이미지 프롬프트 의존성 명시적 증폭
- **PAI**: 이미지 토큰에 대한 주의 가중치 강화

#### 4.4.4 기타 방법
- **OPERA**: Over-trust 패널티 + Retrospection-Allocation
- **Skip '\n'**: 문단 구분 '\n' 생성 회피로 환각 감소
- **RAG**: 외부 지식 검색으로 환각 감소

#### 4.4.5 사후 교정 (Post-hoc Correction)
**Woodpecker**:
```
단계:
1. 핵심 개념 추출
2. 질문 생성
3. 전문가 모델로 시각적 검증
4. 시각적 주장 생성
5. 환각 교정
```

---

## 5. 기존 방법들과의 차이점

### 5.1 LLM 환각 연구와의 차이

| 측면 | LLM 환각 | MLLM 환각 |
|------|----------|----------|
| **초점** | 사실적 정확성 | 교차 모달 일관성 |
| **검증** | 외부 지식 베이스 | 시각적 콘텐츠 |
| **유형** | 사실성, 충실성 | 카테고리, 속성, 관계 |
| **원인** | 주로 데이터, 학습 | 데이터+모델+학습+추론 전 과정 |

### 5.2 기존 MLLM 환각 서베이와의 차이

- **더 세분화된 분류**: 계층적이고 세밀한 환각 원인 분류
- **모델 아키텍처 불특정**: 특정 아키텍처에 국한되지 않고 다양한 요인 분석
- **원인-완화 연결**: 완화 전략이 원인과 직접 연결됨

---

## 6. 한계점 및 미래 연구 방향

### 6.1 데이터 중심 과제
- 고품질, 다양한 학습 데이터 수집/증강/교정 기술 개발 필요
- 데이터 편향 제거 및 다양성 확보

### 6.2 교차 모달 정렬
- 모달리티 간 표현 정렬 방법 개선
- 더 진보된 아키텍처 및 학습 목표 설계

### 6.3 표준화된 벤치마크 부재
- Yes/No 이진 QA 방식은 실제 사용과 괴리
- 생성 태스크 평가는 외부 모델 의존
- 이론적으로 타당하고 사용하기 쉬운 표준 벤치마크 필요

### 6.4 환각을 기능으로 재해석
- 환각 = LLM의 "꿈꾸는" 본질적 특성
- 창의적 응용에서의 활용 가능성
- 벤치마크 최적화 → 인간 경험 최적화로 목표 전환

### 6.5 해석 가능성 및 신뢰성
- 환각 완화 방법들이 주로 경험적 관찰에 기반
- 모델 내부 메커니즘 이해 필요
- 생성 과정 시각화 및 추적 기술 개발

### 6.6 윤리적 고려사항
- 환각으로 인한 잘못된 정보 생성 위험
- 편향, 프라이버시, 사회적 영향 고려
- 책임 있는 AI 실천 필요

---

## 핵심 용어 정리

| 용어 | 설명 |
|------|------|
| **MLLM** | Multimodal Large Language Model, 멀티모달 대규모 언어모델 |
| **LVLM** | Large Vision-Language Model, 대규모 비전-언어 모델 |
| **환각(Hallucination)** | 시각적 콘텐츠와 일치하지 않는 텍스트 생성 |
| **객체 환각(Object Hallucination)** | 이미지에 없는 객체 언급 또는 잘못된 객체 설명 |
| **CHAIR** | Caption Hallucination Assessment with Image Relevance |
| **POPE** | Polling-based Object Probing Evaluation |
| **VCD** | Visual Contrastive Decoding |
| **Q-Former** | 학습 가능한 쿼리 기반 교차 모달 인터페이스 |
| **SFT** | Supervised Fine-Tuning, 지도 학습 미세조정 |
| **RLHF** | Reinforcement Learning from Human Feedback |
| **DPO** | Direct Preference Optimization |

---

## 참고

- **논문 출처**: arXiv:2404.18930v2 [cs.CV] 1 Apr 2025
- **저자**: Zechen Bai, Pichao Wang, Tianjun Xiao, Tong He, Zongbo Han, Zheng Zhang, Mike Zheng Shou
- **기관**: Show Lab (NUS), Amazon AGI, AWS Shanghai AI Lab
- **GitHub**: https://github.com/showlab/Awesome-MLLM-Hallucination

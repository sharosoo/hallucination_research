# 2026-01-20 실험 결론 및 향후 계획

## 1. 실험 요약

### 원래 가설
> Corpus coverage가 낮으면 Energy 효과적, 높으면 SE 효과적

QuCo-RAG 논문 기반 triplet extractor로 corpus coverage를 계산하고, coverage 백분위별로 SE와 Energy의 AUROC를 비교.

### 실험 결과

**TruthfulQA - Coverage 백분위별 AUROC**

| 백분위 | n | SE | Energy | 우세 |
|--------|---|-----|--------|------|
| 하위 20% | 40 | 0.639 | 0.556 | SE |
| 20-40% | 40 | 0.639 | 0.556 | SE |
| 40-60% | 37 | 0.469 | 0.310 | SE |
| 60-80% | 0 | - | - | - |
| 상위 20% | 83 | 0.678 | 0.680 | Tie |

**HaluEval - Coverage 백분위별 AUROC**

| 백분위 | n | SE | Energy | 우세 |
|--------|---|-----|--------|------|
| 하위 20% | 40 | 0.458 | 0.598 | Energy |
| 20-40% | 40 | 0.458 | 0.598 | Energy |
| 40-60% | 120 | 0.458 | 0.598 | Energy |
| 60-80% | 0 | - | - | - |
| 상위 20% | 41 | 0.544 | 0.598 | Energy |

### 그래프

*(Plotly 인터랙티브 그래프: `experiment_notes/exp05_quintile_analysis/quintile_analysis.ipynb` 실행)*

---

## 2. 결론

### 2.1 Corpus Coverage는 통계적으로 무의미

- **TruthfulQA**: 모든 백분위에서 SE 우세
- **HaluEval**: 모든 백분위에서 Energy 우세
- Coverage 값과 무관하게 **데이터셋 전체 특성**이 결정적

### 2.2 데이터셋 특성 차이

| 지표 | TruthfulQA | HaluEval |
|------|------------|----------|
| SE 평균 | **0.92** (높음) | **0.37** (낮음) |
| Zero-SE 비율 | 20.5% | **57%** |
| Hallucination rate | 82.5% | 10.5% |

- **TruthfulQA**: 모델이 혼란 → 다양한 응답 → SE 작동
- **HaluEval**: 모델이 확신 → 일관된 응답 → SE 작동 안 함, Energy 필요

### 2.3 핵심 문제

**"어떤 방법이 효과적일지 미리 예측할 수 없다"**

- Corpus coverage로는 예측 불가 (실험으로 확인)
- SE 분포를 보려면 이미 SE를 계산해야 함 (닭과 달걀)
- 개별 샘플 수준에서 적응적 선택이 필요

---

## 3. 향후 연구 방향: 학습 기반 가중치 분류기

### 3.1 아이디어

SE와 Energy를 **둘 다 계산**하고, 학습된 분류기가 **가중치를 결정**:

```
Score = w(x) × Energy + (1 - w(x)) × SE

w(x) = Classifier(features of x)
```

### 3.2 exp06 실험 결과 (2026-01-21)

**같은 데이터셋 Test**:
- Combined 데이터셋에서 LogisticRegression_ext가 **AUROC 0.91** 달성

**Cross-dataset 일반화 (한계)**:
- TruthfulQA → HaluEval: Energy_only (0.60) > 학습 모델
- HaluEval → TruthfulQA: SE_only (0.62) > 학습 모델
- **결론**: 학습 모델은 같은 분포 내에서만 효과적

---

## 4. 관련 연구 (고인용 논문 중심)

### 4.1 핵심 기반 방법론

#### Semantic Entropy (Farquhar et al., Nature 2024) ⭐ 816 citations

**논문**: Detecting hallucinations in large language models using semantic entropy

**링크**: https://arxiv.org/abs/2302.09664 | Nature 2024

**핵심 아이디어**: 의미적으로 동등한 응답들을 클러스터링하고, 클러스터 분포의 엔트로피 계산

**수식**:
$$SE(x) = -\sum_{C \in \Omega} p(C|x) \log p(C|x)$$

여기서:
- $\Omega$: 의미적 클러스터 집합
- $p(C|x) = \sum_{s \in C} p(s|x)$: 클러스터 확률

**의미적 클러스터링**: NLI 모델(DeBERTa-MNLI)로 양방향 entailment 판정

**한계**: 모델이 확신하며 틀릴 때 (일관된 오답) SE ≈ 0 → 탐지 실패

---

#### Semantic Entropy 원논문 (Kuhn et al., ICLR 2023) ⭐ 474 citations

**논문**: Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in NLG

**링크**: https://arxiv.org/abs/2302.09664 | ICLR 2023 Spotlight

**핵심 기여**: 언어적 불변성(linguistic invariances)을 고려한 비지도 불확실성 측정 제안

---

### 4.2 Hallucination Detection Benchmarks & Methods

#### SelfCheckGPT (Manakul et al., EMNLP 2023) ⭐ 1,177 citations

**논문**: Zero-Resource Black-Box Hallucination Detection for Generative LLMs

**링크**: https://arxiv.org/abs/2303.08896

**핵심 아이디어**: 여러 샘플 간 일관성으로 환각 탐지 - 모델이 "아는" 사실은 일관되고, 환각은 샘플마다 다름

**수식**:
$$\text{SelfCheck}(s) = \frac{1}{N} \sum_{i=1}^{N} \mathbb{1}[\text{contradict}(s, s_i)]$$

**우리 연구와의 관련성**: SE와 유사한 sampling-based 접근, black-box 적용 가능

---

#### FActScore (Min et al., EMNLP 2023) ⭐ 1,008 citations

**논문**: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation

**링크**: https://arxiv.org/abs/2305.14251

**핵심 아이디어**: 생성된 텍스트를 atomic facts로 분해 후 각각의 사실성 검증

**수식**:
$$\text{FActScore} = \frac{1}{|A|} \sum_{a \in A} \mathbb{1}[\text{supported}(a, K)]$$

여기서 $A$는 atomic facts, $K$는 knowledge source

---

#### TruthfulQA (Lin et al., ACL 2022) ⭐ 1,725 citations

**논문**: Measuring How Models Mimic Human Falsehoods

**링크**: https://arxiv.org/abs/2109.07958

**핵심 기여**: 인간의 오해를 유도하는 817개 질문으로 구성된 벤치마크. 큰 모델일수록 덜 truthful한 경향 발견.

---

### 4.3 Calibration & Self-Knowledge

#### "Models Know What They Know" (Kadavath et al., 2022) ⭐ 880 citations

**논문**: Language Models (Mostly) Know What They Know

**링크**: https://arxiv.org/abs/2207.05221

**핵심 아이디어**: P(True) scoring과 P(IK) prediction으로 모델의 자기 평가 능력 검증

**수식**:
$$P(\text{True}) = p(\text{"True"} | \text{question}, \text{proposed answer})$$

**발견**: 큰 모델은 적절히 포맷하면 잘 calibrated됨

---

#### Verbalized Uncertainty (Lin et al., TMLR 2022) ⭐ 547 citations

**논문**: Teaching Models to Express Their Uncertainty in Words

**링크**: https://arxiv.org/abs/2205.14334

**핵심 아이디어**: 모델이 logit 없이 자연어로 확신도 표현 ("90% confidence")

**발견**: verbalized confidence가 잘 calibrated됨

---

#### CALM (Schuster et al., NeurIPS 2022) ⭐ 222 citations

**논문**: Confident Adaptive Language Modeling

**링크**: https://arxiv.org/abs/2207.07061

**핵심 아이디어**: 확신도 기반 early exit으로 동적 compute 할당

**수식**:
$$\text{exit if } \max_v p(v|x) > \tau$$

**결과**: 성능 유지하며 3배 speedup

---

### 4.4 Surveys

#### Hallucination Survey (Huang et al., 2023) ⭐ 3,843 citations

**논문**: A Survey on Hallucination in LLMs: Principles, Taxonomy, Challenges

**링크**: https://arxiv.org/abs/2311.05232 | ACM TOIS

**핵심 기여**: Factuality vs Faithfulness hallucination 분류, LLM lifecycle 전체에서의 원인 분석

---

#### Siren's Song Survey (Zhang et al., 2023) ⭐ 762 citations

**논문**: Siren's Song in the AI Ocean: A Survey on Hallucination in LLMs

**링크**: https://arxiv.org/abs/2309.01219

**핵심 기여**: 탐지/설명/완화 방법 종합, 벤치마크 분류

---

### 4.5 최신 연구 (저인용, 참고용)

> ⚠️ 아래 논문들은 2025-2026년 preprint로 인용수가 낮음 (< 10). 아이디어 참고용으로만 사용.

| 논문 | 핵심 아이디어 | 링크 |
|------|-------------|------|
| Semantic Energy (Ma et al., 2025) | Energy-based uncertainty, SE 실패 시 보완 | arXiv:2412.07965 |
| KLE (Nikitin et al., 2024) | Kernel 기반 SE 확장, 연속적 유사도 | arXiv:2405.20003 |

---

## 5. 실험 계획

### Phase 1-3: 완료 ✅
- [x] Corpus coverage 기반 적응적 가중치 (실패)
- [x] 학습 기반 분류기 (같은 분포 내에서만 효과)

### Phase 4: 다음 단계 (TODO)
- [ ] SelfCheckGPT 방식 적용 (sampling consistency)
- [ ] P(True) / verbalized confidence 활용
- [ ] 더 큰 데이터셋으로 검증 (WikiBio, CNN/DM)

---

## 6. 파일 구조

```
hallucination_lfe/
├── 260120_plan.md              # 이 문서
├── experiment_notes/
│   ├── exp04_corpus_adaptive/  # Corpus 실험 (결론: 무의미)
│   ├── exp05_quintile_analysis/# 백분위 분석 & 결론
│   └── exp06_weight_classifier/# 분류기 학습 실험
└── references/                 # 논문 요약
    ├── KLE_summary_korean.md
    └── ...
```

---

## 7. 참고문헌 (인용수 순)

1. Huang et al. (2023). A Survey on Hallucination in LLMs. *ACM TOIS*. **3,843 citations**
2. Lin et al. (2022). TruthfulQA. *ACL 2022*. **1,725 citations**
3. Manakul et al. (2023). SelfCheckGPT. *EMNLP 2023*. **1,177 citations**
4. Min et al. (2023). FActScore. *EMNLP 2023*. **1,008 citations**
5. Kadavath et al. (2022). Language Models Know What They Know. **880 citations**
6. Farquhar et al. (2024). Semantic Entropy. *Nature*. **816 citations**
7. Zhang et al. (2023). Siren's Song Survey. **762 citations**
8. Lin et al. (2022). Verbalized Uncertainty. *TMLR*. **547 citations**
9. Kuhn et al. (2023). Semantic Uncertainty. *ICLR 2023*. **474 citations**
10. Schuster et al. (2022). CALM. *NeurIPS 2022*. **222 citations**

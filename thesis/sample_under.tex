% 서울대학교 전기공학부 (전기정보공학부) 학사 학위논문
% LaTeX 양식 샘플
\RequirePackage{fix-cm} % fix-cm 패키지는 documentclass 이전에 넣는다.
% oneside : 단면 인쇄용
% 학사 학위논문에서는 단면을 쓴다.
% ko : 국문 논문 작성
% under : 학사
\documentclass[oneside,ko,under,twocolumn]{snuthesis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% 목차 양식을 변경하는 코드
%% subfigure (subfig) package 사용 여부에 따라
%% tocloft의 옵션을 다르게 지정해야 한다.
%\usepackage[titles,subfigure]{tocloft} % when you use subfigure package
\usepackage[titles]{tocloft} % when you don't use subfigure package
\makeatletter
\if@snu@ko
	\renewcommand\cftchappresnum{제~}
	\renewcommand\cftchapaftersnum{~장}
	\renewcommand\cftfigpresnum{그림~}
	\renewcommand\cfttabpresnum{표~}
\else
	\renewcommand\cftchappresnum{Chapter~}
	\renewcommand\cftfigpresnum{Figure~}
	\renewcommand\cfttabpresnum{Table~}
\fi
\makeatother
\newlength{\mytmplen}
\settowidth{\mytmplen}{\bfseries\cftchappresnum\cftchapaftersnum}
\addtolength{\cftchapnumwidth}{\mytmplen}
\settowidth{\mytmplen}{\bfseries\cftfigpresnum\cftfigaftersnum}
\addtolength{\cftfignumwidth}{\mytmplen}
\settowidth{\mytmplen}{\bfseries\cfttabpresnum\cfttabaftersnum}
\addtolength{\cfttabnumwidth}{\mytmplen}
%% 목차 양식을 변경하는 코드 끝
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 다른 패키지 로드
%% http://faq.ktug.or.kr/faq/pdflatex%B0%FAlatex%B5%BF%BD%C3%BB%E7%BF%EB
%% 필요에 따라 직접 수정 필요
\ifpdf
	\input glyphtounicode\pdfgentounicode=1 %type 1 font사용시
	%\usepackage[pdftex,unicode]{hyperref}
	\usepackage[pdftex]{graphicx}
	%\usepackage[pdftex,svgnames]{xcolor}
\else
	%\usepackage[dvipdfmx,unicode]{hyperref}
	\usepackage[dvipdfmx]{graphicx}
	%\usepackage[dvipdfmx,svgnames]{xcolor}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{lipsum} % lorem ipsum


\title{딥러닝 기반 object tracking 알고리즘의\\%
경량화 및 최적화}

\schoolko{서울대학교 공과대학}
\departmentko{전기·정보공학부}

%% 저자 이름 Author's(Your) name
\author{최병욱}
\author*{최~병~욱} % Insert space for Hangul name.

%% 학번 Student number
\studentnumber{2017-16835}

%% 지도교수님 성함 Advisor's name
\advisor{이혁재}
\advisor*{이~혁~재} % Insert space for Hangul name.

%% 학위 수여일 Graduation date
%% 표지에 적히는 날짜.
%% 학위 수여일이 아니라 논문 발간년도를 적어야 할 수도 있음.
\graddate{2023~년~8~월}

% 논문 인준일 Approval date
\approvaldate{2023~년~6~월~26일}

\usepackage{changepage}

\begin{document}
\pagenumbering{Roman}
\makefrontcover
\makeapproval

\cleardoublepage
\pagenumbering{roman}
% 초록 Abstract
\keyword{Object Tracking, YOLOv5, Deep SORT, Data Augmentation, Dataset Filtering, Merged Data Augmentation}
\begin{abstract}
    본 연구는 UAV에서 촬영한 영상에서 공을 소유한 사람을 추적하는 object tracking task를 더 정확하게 수행하기 위한 개선을 진행하였다. object tracking 모듈은 object detecion을 담당하는 Yolo와 multi object tracking을 수행하는 Deep SORT로 구성된다. object detecion 모듈에서 발생하는 merged object detecion, false positive detection 문제를 경감시키기 위해 task 상황에 적합한 dataset으로 object detecion 모델 학습을 진행하였다. 이러한 dataset을 구성하기 위해 dataset filtering 및 Copy-paste augmentation을 응용한 merged data augmentation을 도입 및 적용하였다. 본 논문은 연구 대상 task에 대한 정의, Object Tracking 모듈과 Copy-Paste augmentation에 대한 간략한 소개를 포함한다. 또한, 본 연구에서 진행한 dataset filtering 및 merged data augmentation에 대한 방법론과 적용 전후의 object detection 및 task 수행 성능을 비교 분석한다.

\end{abstract}

\tableofcontents
\listoftables
\listoffigures

\cleardoublepage
\pagenumbering{arabic}


\chapter{서론}

    \section{연구 배경 및 목적}

        본 연구의 목적은 UAV에서 촬영한 영상에서 공과 사람을 추적하는 object tracking task에 대해, 알고리즘을 경량화 및 최적화하는 것이다. object tracking은 객체를 프레임 단위로 추적하는 task로, 이를 위해 객체 탐지(object detection)와 객체 추적(object tracking)을 수행한다. 본 연구에서는 객체 탐지 모델로 YOLOv5를, 객체 추적 알고리즘으로 Deep SORT \cite{deepsort}를 사용하였다.

        Task에 대한 구체적은 설명은 다음과 같다. 목적은 각 frame에서 공을 가지고 있는 사람을 추적하는 것이다. input은 UAV가 촬영한 영상이고, input 영상은 두 종류의 상황이 존재한다. 그림~\ref{fig:video_fixed_person}은 사람과 카메라가 고정된 상황에서 촬영한 영상이고, 그림~\ref{fig:video_moving_person}은 사람 및 카메라가 움직이는 상황에서 촬영한 영상이다. output은 영상의 frame index, 공을 소유하고 있는 사람의 id, 공 id의 배열이 된다. 이떄 output에는 공을 소유하고 있는 사람이 바뀌는 frame만을 기록한다. 5 frame 간격 이내에서 정답 output과 예측 output이 일치하면 정확히 기록한 것으로 간주한다. Task의 정확도 측정은 여러개의 input에 대해 평균을 score를 측정하여 산출한다. score는 다음과 같이 계산된다.

        \[
        \text{{correct\_output}} = (frames\:in\:output\:|\:match\:with\:answer\:within\:5\:frames)
        \]
        \[
            \text{{score}} = \frac{{\text{{len(correct\_output)}}}}{{\text{{len(answer)}}}}
        \]

        \begin{figure}[htbp]
            \centering
            \begin{minipage}[b]{0.48\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/video_fixed_person.png}
                \caption{사람과 카메라가 고정된 상황에서의 영상}
                \label{fig:video_fixed_person}
            \end{minipage}
            \hfill
            \begin{minipage}[b]{0.48\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/video_moving_person.png}
                \caption{사람 및 카메라가 움직이는 상황에서의 영상}
                \label{fig:video_moving_person}
            \end{minipage}
        \end{figure}


        본 연구에서는 먼저 \ref{ch:main}~장의 \ref{sec:previous_work}~절에서 선행 연구를 살펴보고, \ref{sec:problem}~절에서는 object detection 모델의 문제점을 분석한다. 이이서 \ref{sec:dataset_improvement}~절에서 object detection 모델의 성능을 향상시키기 위해 task 상황에 맞는 데이터셋을 구성하는 방법을 제시한다. \ref{sec:results}~절에서는 제시한 방법을 통해 측정된 score 및 문제점의 해소 여부를 확인해본다. 마지막으로 \ref{ch:conclusion}~장 결론에서 본 연구의 결론 및 추후 연구 방향을 제시한다.


\chapter{본론}{\label{ch:main}}
    \section{선행연구}{\label{sec:previous_work}}
        \subsection{Object Tracking 모듈 (yolov4 + deepsort) \cite{real_time_fruit}}
            YOLO와 Deep SORT로 구성된 object tracking 모듈은 그림~\ref{fig:object_tracking_module}과 같은 구조로 처리된다.
            
            YOLO는 (You Only Look Once)는 높은 정확성과 속도를 보여주는 object detection 모델으로, 실시간 영상 object tracking을 위해 필요한 object detection 모듈로 사용되기에 적합하다.

            Deep SORT (Simple Online and Real-Time Tracking)는 multiple object tracking을 위해 설계된 SORT 알고리즘의 확장이다. Deep SORT는 기존 SORT 알고리즘의 motion-based 지표와 뉴럴 network에서 얻게되는 apperance-based 지표를 모두 고려하여, multiple object tracking 성능을 향상 시키게된다.


            \begin{figure}[htbp]
                \centering
                \includegraphics[width=0.8\textwidth]{images/object_tracking_module.png}
                \caption{object tracking 모듈 구조 (yolov4 + deepsort)\cite{real_time_fruit}}
                \label{fig:object_tracking_module}
            \end{figure}


        \subsection{Copy-Paste augmentation \cite{simple_copy_paste}}
            Copy-Paste augmentation은 image segmentation task에서 사용되는 간단하고 효과적인 data augmentation 기법 중 하나이다. 한 이미지에 존재하는 object를 복사하여 다른 이미지에 붙여넣는 방식으로 여러 이미지에 존재하는 object들을 조합하여 새로운 이미지를 생성하게 된다. 다른 data augmentation 기법과 달리 Copy-Paste augmentation는 bounding box 내부의 모든 픽셀을 가져오는 것이 아닌, segmentation annotation 내부에 해당하는 픽셀만을 가져온다. Copy-Paste augmentation의 이점은 image segmentation 모델 학습 과정에 추가 비용없이 쉽게 도입이 가능하기 때문에, label이 부족한 클래스에 대해 추가적으로 학습용 dataset을 효과적으로 생성할 수 있다는 점에 있다. 

    \section{연구 대상의 문제점 및 연구 방향}{\label{sec:problem}}
        Task를 위한 샘플 코드\cite{sample_code} 를 inference한 결과, 몇가지 문제점을 찾을 수 있었다. Object Detection 부분에서는 공의 False Positive가 발생하는 문제와 여러 Object가 1개의 Object로 detect되는 문제가 발생하였고, Multi-Object Tracking 부분에서는 여러 사람이 겹치는 경우, 공을 가지지 않은 사람이 공을 소유하는 것으로 판정하는 문제가 있었다.

        \begin{figure}[htbp]
            \centering
            \begin{minipage}[b]{0.48\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/fp_detection.png}
                \caption{false positive detection 문제}
                \label{fig:fp_detection}
            \end{minipage}
            \hfill
            \begin{minipage}[b]{0.48\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/merged_detection.png}
                \caption{merged object의 중복 detection 문제}
                \label{fig:merged_detection}
            \end{minipage}
        \end{figure}

        그림~\ref{fig:fp_detection}은 공이 아닌 다른 물체가 공으로 잘못 detect된 경우이다. 그림~\ref{fig:merged_detection}은 여러 사람이 공을 가지고 있는 경우, 1개의 Object로 detect되는 문제이다. 이렇듯 공과 사람에서의 Detection 성능이 낮은 것이 Object Tracking에서 정확도가 낮게 측정되는 이유 중 하나로 발견할 수 있었다. 따라서 이를 개선하기 위해 Object Detection 모듈의 정확도를 올려 전체 task score를 증가시키는 것을 목표로 연구를 수행하였다.


    \section{Object Detection 모델의 학습 Dataset 개선}{\label{sec:dataset_improvement}}
        \subsection{Dataset filtering} \label{sec:dataset_filtering}
            먼저 task 상황에 맞는 학습 dataset을 선정하였다. (COCO dataset, train2017) 전체 118k장의 이미지 중에 person, sports ball class가 포함된 이미지 62k장을 선별하였다.
            이후, standing person object를 선별하기 위해 dataset에 대해 탐색적 데이터 분석 및 filtering을 수행하였다. 

            수행한 필터링 항목은 다음과 같다.
            \begin{itemize}
                \item \textbf{number of detections ≤ 10} : 10개 이상의 detection이 존재하는 이미지는 이미지 내의 object가 많아서 object segmentation이 어려울 것으로 판단하였다.
                \item \textbf{Exclude edge detections} : 이미지의 가장자리에 위치한 object는 이미지 내의 object가 아닐 가능성이 높다고 판단하였다.
                \item \textbf{Aspect ratio ≥ 1.7} : standing person object는 보통 세로가 더 긴 형태를 가지고 있기 때문에, 세로로 긴 object를 선별하기 위해 aspect ratio가 1.7 이상인 object를 선별하였다.
                \item \textbf{0.01 ≤ Bbox area ≤ 0.5} : 이미지 내에서 과도하게 크거나 작은 object는 task 상황에 적합하지 않다고 판단하였다.
            \end{itemize}

            위와 같은 조건들로 학습 dataset을 filtering 하였고, 62k장의 이미지 중 11k장의 이미지를 선별할 수 있었다. 선별된 이미지 중 1장의 예시를 그림~\ref{fig:coco_standing_person_object}에 나타내었다.

            \begin{figure}[htbp]
                \centering
                \includegraphics[width=0.8\textwidth]{images/coco_standing_person_object.png}
                \caption{dataset filtering을 통해 선별한 standing person object 예시}
                \label{fig:coco_standing_person_object}
            \end{figure}
        
        \subsection{Data augmentation}{\label{sec:data_augmentation}}

            Task 상황에 적합한 학습 dataset을 구성하기 위해, Copy-paste augmentation~\cite{simple_copy_paste}를 적용하여 dataset을 확장하였다. 학습 dataset으로 이용한 COCO dataset은 object segmentation task에도 사용되어 각 이미지의 object 마다    segmentation annotation이 존재한다. 이를 이용해 원본 이미지를 segmentation map으로 masking 하여 segmented person 이미지들을 분리해내고, Task input 영상과 유사하게 여러 사람들이 공을 가지고 있는 이미지를 생성하여 학습 sdataset으로 사용하는 방법을 도입하였다. 

            \begin{figure}[htbp]
                \centering
                \begin{minipage}[b]{0.48\textwidth}
                    \centering
                    \includegraphics[width=\textwidth]{images/segmentation_original.png}
                    \caption{segmetation 적용 전의 원본 이미지}
                    \label{fig:segmentation_original}
                \end{minipage}
                \hfill
                \begin{minipage}[b]{0.48\textwidth}
                    \centering
                    \includegraphics[width=\textwidth]{images/segmentation_masked.png}
                    \caption{segmentation mask 이미지}
                    \label{fig:segmentation_masked}
                \end{minipage}
            \end{figure}
            
            \begin{figure}[htbp]
                \centering
                \includegraphics[width=0.7\textwidth]{images/segmentation_result.png}
                \caption{segmentation mask를 적용한 이미지}
                \label{fig:segmentation_result}
            \end{figure}
            
            그림~\ref{fig:segmentation_original}과 같은 원본 이미지에 segmentation annotation에 따라 그림~\ref{fig:segmentation_masked}과 같은 image segmentation mask를 얻을 수 있었다. 이를 이용해 원본 이미지를 masking하면 최종적으로 그림~\ref{fig:segmentation_result}와 같은 이미지가 생성된다. 원본 이미지에서 배경이 제거된 segmented person image를 이용해 merged dataset 생성을 진행하였다.

            \begin{figure}[htbp]
                \centering
                \includegraphics[width=0.7\textwidth]{images/merged_dataset.png}
                \caption{merged dataset 예시}
                \label{fig:merged_dataset}
            \end{figure}

            그림~\ref{fig:merged_dataset}은 merge augmentation을 통해 생성된 dataset의 예시이다. person objects의 수를 3$\sim$7개, ball objects의 수를 1$\sim$3개로 설정 후 merge augmented dataset을 3k장을 생성하였다. Dataset filtering을 이용해 선별한 11k장의 이미지와, 이 이미지들을 원본으로 이용해 생성한 merged dataset 3k장의 이미지를 object detection 모델 (YOLOv5) 학습에 사용하였다. 
            
    \section{연구결과}{\label{sec:results}}
        \subsection{Dataset setup에 따른 성능 비교}

            표~\ref{tab:map_coco}은 각 setup에 따른 image dataset으로 학습한 YOLOv5 model weight으로 setup별 test dataset에 대해 test를 수행한 결과이다. \textit{COCO(person, ball)} setup은 COCO dataset에서 person과 ball class가 포함된 이미지 62k장의 dataset을 이용한 것을 의미한다. \textit{COCO(standing person, ball)} setup은 \textit{COCO(person, ball)} setup에 \ref{sec:dataset_filtering}에서 설명한 dataset filtering을 적용해 선별한 이미지를 이용한 것을 의미한다. 또한 \textit{COCO(standing person, ball) w/ Merged} setup은 \textit{COCO(standing person, ball)} setup에 merged dataset 약 3k장을 추가로 이용한 것을 의미한다.
            % add margin
            
            \begin{figure}[htbp]
                \centering
                \begin{minipage}[b]{0.48\textwidth}
                    \centering
                    \includegraphics[width=\textwidth]{images/result_detection_on_coco.png}
                    \caption{detection 예시 (coco dataset)}
                    \label{fig:result_detection_on_coco}
                \end{minipage}
                \hfill
                \begin{minipage}[b]{0.48\textwidth}
                    \centering
                    \includegraphics[width=\textwidth]{images/result_detection_on_frame_image_dataset.png}
                    \caption{detection 예시 (frame image dataset)}
                    \label{fig:result_detection_on_frame_image_dataset}
                \end{minipage}
            \end{figure}

            \begin{table}[htbp]
                \centering
                \begin{tabular}{ p{7.5cm}|r r r}
                    \hline
                    Setup &  \#   Images         &  mAP@.5&  mAP@.5:95\\
                    \hline
                    \hline
                    Baseline                    &  -     & 79.9 &  53.9\\
                    \hline
                    COCO(person, ball)          &  62372  & 89.9 &  65.4\\
                    \hline
                    COCO(standing person, ball) &  11033  & 87.1 &  61.4\\
                    \hline
                    COCO(standing person, ball) w/ Merged & 13651 & 93.3 &  76.0\\
                    \hline
                \end{tabular}
                \caption{학습 dataset setup에 따른 object detection model별 mAP score 비교}
                \label{tab:map_coco}
            \end{table}



            각 Setup 별로 학습 dataset이 상이해 test dataset도 다르기 때문에 직접적인 성능 비교는 어렵지만, setup별 모델이 약 90의 mAP@.5 score를 가진다는 점을 통해 각 모델들이 학습 dataset으로 충분히 학습되었다는 점을 알 수 있다. 또한 \textit{COCO(standing person, ball) w/ Merged} setup이 \textit{COCO(standing person, ball)} setup에 비해 6.2의 mAP@.5 score 향상을 보이는 점을 통해, merged dataset을 추가로 이용해 학습한 후자의 모델이 dataset을 더 잘 학습하였다고 볼 수 있다.

            \begin{table}[htbp]
                \centering
                \begin{tabular}{ p{7.5cm}|r r}
                    \hline
                    Setup &                      mAP@.5&  mAP@.5:95\\
                    \hline
                    \hline
                    Baseline                   & 95.9 &  71.8\\
                    \hline
                    COCO(person, ball)         & 78.7 &  53.0\\
                    \hline
                    COCO(standing person, ball)& 79.5 &  54.1\\
                    \hline
                    COCO(standing person, ball) w/ Merged & \textbf{{(+0.6)}} 96.5} & \textbf{{(+5.8)}} 77.6} \\
                    \hline
                \end{tabular}
                \caption{학습 dataset setup에 따른 test mAP score 비교 (frame image dataset 대상)}
                \label{tab:map_frame}
            \end{table}

            표~\ref{tab:map_frame}는 task 상황 test용 영상을 frame 별로 저장한 dataset으로 test를 한 결과를 나타낸다. frame image dataset은 task input 영상과 동질적인 object (standing person 및 ball)를 포함하므로, frame image dataset에 대한 test 결과를 통해, 전체 object tracking 모듈에서 사용될 object detection 모델의 실질적인 성능을 확인해 볼 수 있다. 
            COCO(person, ball)과 COCO(standing person, ball)의 경우, Baseline보다 정확도가 떨어지게 된다. COCO(person, ball)에 비해 COCO(standing person, ball)이 근소하게 정확도가 높게 측정되어, standing person 필터링의 적용이 성능 향상에 기여하였다고 판단할 수 있다. 또한 w/ Merged setup의 경우, mAP@.5에서 Baseline의 score 95.9에 비해 0.6 증가한 95.9, mAP@.5:95에서 Baseline의 score 71.8에 비해 5.8 증가한 77.6으로 측정되어, merge data augmentation이 detection 성능 향상에 효과를 보임을 알 수 있다.
            
            \begin{table}[htbp]
                \centering
                \begin{tabular}{ p{3cm}| r r r r r|}
                    \cline{2-6}
                    & \multicolumn{5}{c|}{sports ball}\\
                    \hline
                    Setup         & \# labels    & P     & R     & TP & FP\\
                    \hline
                    \hline
                    Baseline     & 558        & 0.980 & 0.898 & 501 & 10\\
                    \hline
                    w/ Merged    & 558        & 0.985 & 0.923 & 515 & \textbf{{(-2)}} 8}\\
                    \hline
                \end{tabular}
                
                \medskip
                \textbf{*} \textit{\w/ Merged} : \textit{COCO(standing person, ball) w/ Merged} setup

                \caption{Sports ball detection 결과 비교}
                \label{tab:score_sportsball}
            \end{table}
            

            \begin{table}[htbp]
                \centering
                \begin{tabular}{ p{3cm}|r r r r r | r}
                    \hline
                    Setup         & 5p5b & 4p1b & 5p4b & 5p2b & 7p3b & Avg. Score \\
                    \hline
                    \hline
                    Baseline     & 0.20 & 0.79 & 0.75 & 0.23 & 0.28 & 0.45\\
                    \hline
                    w/ Merged   & 0.21 & 0.93 & 0.72 & 0.30 & 0.29 & \textbf{{(+0.04)}} 0.49}\\
                    \hline
                \end{tabular}
                
                \medskip
                \textbf{*} \textit{\w/ Merged} : \textit{COCO(standing person, ball) w/ Merged} setup

                \caption{Task score 비교}
                \label{tab:score}
            \end{table}

            표~\ref{tab:score_sportsball}은 Baseline과 w/ Merged setup의 sports ball detection 결과를 정리한 표이다. sports ball의 false positive detection이 Baseline에서 10개인 것에 비해 w/ Merged에서는 8개로 2개 감소한 것을 확인할 수 있다. 


            표~\ref{tab:score}은 Baseline과 w/ Merged setup의 전체 task score를 비교한 결과이다. Test 대상 영상 5개에 대해 4개 영상에서 w/ Merged setup이 높은 score를 보였고, 평균 score가 0.49로 Baseline의 평균 score 0.45 대비 0.04 증가한 것을 확인할 수 있다. 이를 통해 object detection 성능 향상이 전체 object tracking task의 성능 향상으로 이어짐을 확인할 수 있었다.

            \begin{figure}[htbp]
                \centering
                \includegraphics[width=0.9\textwidth]{images/result_comparision_merged_object.png}
                \caption{Baseline과 w/ Merged setup에서 merged object 대상 detection 비교}
                \label{fig:result_comparision_merged_object}
            \end{figure}

            \begin{figure}[htbp]
                \centering
                \includegraphics[width=0.9\textwidth]{images/result_comparision_false_positive.png}
                \caption{Baseline과 w/ Merged setup에서 false positive detection 비교}
                \label{fig:result_comparision_false_positive}
            \end{figure}

            그림~\ref{fig:result_comparision_merged_object}과 그림~\ref{fig:result_comparision_false_positive}은 각각 샘플영상의 같은 frame에서 Baseline과 w/ Merged 모델의 detection 결과를 비교한 사진이다. 그림~\ref{fig:result_comparision_merged_object}을 통해 겹쳐져 있는 person object들을 w/ Merged 모델에서 분리하여 detect함을 확인할 수 있다. 이를 통해 앞서 분석한 문제점 중 Merged object detection이 경감되었음을 알 수 있다. 또한 그림~\ref{fig:result_comparision_false_positive}를 통해 Baseline에서 사람의 종아리를 sports ball로 detect하는 false positive가 w/ Merged에서는 제거되었음을 확인할 수 있다. 이를 통해 앞서 분석한 문제점 중 False Positive detection 문제점이 경감되었음을 알 수 있다. 따라서, \ref{sec:problem}에서 분석한 문제점들이 w/ Merged dataset을 활용한 object detection model 성능 향상을 통해 개선되었음을 확인할 수 있었다.

\chapter{결론}{\label{ch:conclusion}}
    본 연구에서는 UAV 개체 추적 작업에서 발생하는 문제를 해결하기 위해 object detection 성능을 개선하는 방법을 탐구하였다. 샘플코드를 통해 확인한 결과, Object Detection 부분에서는 False Positive와 여러 개체를 하나로 detect하는 문제가 발생하였으며, Multi-Object Tracking 부분에서는 겹치는 개체들을 잘못 판정하는 문제가 있었다. 이러한 문제들을 해결하기 위해 Object Detection 모듈의 정확도를 개선하고자 하였다.

    이러한 목적 달성을 위해 task 상황에 맞는 dataset filtering, merge data augmentation을 도입하여 개선된 dataset을 생성 및 구성하였다. 해당 dataset을 이용해 YOLOv5 object detection 모델을 학습하여 object detection 성능을 증가시킨 것을 확인하였고, 이를 이용해 task score를 측정한 결과, 개선된 모델의 score는 Baseline score인 0.45 대비 0.04 증가한 0.49의 성과를 달성할 수 있었다. 또한, frame 단위에서 Merged object detection과 False Positive detection이 개선되었음을 확인하였다. 결론적으로 object detection, multi-object tracking module로 구성된 object tracking module의 object detection 성능을 개선하여 object tracking 성능의 최적화를 달성하였다.

    향후 연구 방향으로는 다음과 같은 것들이 있다. 첫째로, object의 개수가 많은 상황에 대한 성능 향상이 필요하다. 표~\ref{tab:score}에서 확인할 수 있듯이, 개선된 모델의 성능 향상은 테스트 영상 별로 그 정도의 차이가 존재한다. 공이 여러개 존재하는 상황일수록 성능 향상이 적은 것을 확인할 수 있고, 특히 5p4b영상의 경우 Baseline 모델보다 task score가 더 낮게 측정된 것을 확인할 수 있다. object의 occlusion 대응, merged object에 대한 더 정확한 분리 등을 통해 object의 개수가 많은 상황에서의 성능 확보를 위한 연구가 필요하다. 또한, UAV에서 촬영한 영상을 기반으로 object tracking을 수행하는 task 특성상 에너지 소모가 적은 모델을 사용하는 것이 중요하다. 따라서, 향후 연구에서는 weight pruning, quantization 혹은 knowledge distillation과 같은 방법들을 적용해 모델을 경량화하고자 한다. 

\begin{thebibliography}{00}
\addcontentsline{toc}{chapter}{\bibname}

    \bibitem{yolov4}
    A. Bochkovskiy, C.-Y. Wang, and H.-Y. M. Liao, "YOLOv4: Optimal Speed and Accuracy of Object Detection," 2020. [Online]. Available: \url{https://arxiv.org/abs/2004.10934}.
    
    \bibitem{deepsort}
    Wojke, N., Bewley, A., & Paulus, D. (2017). Simple Online and Realtime Tracking with a Deep Association Metric. In 2017 IEEE International Conference on Image Processing (ICIP) (pp. 3645-3649). IEEE.    

    \bibitem{real_time_fruit} A. I. Parico and T. Ahamed, ``Real Time Pear Fruit Detection 
    and Counting Using YOLOv4 Models and Deep SORT,''
    \emph{Sensors}, vol. 21, no. 7, p. 4803, Jul. 2021. doi: 10.3390/s21144803.

    \bibitem{simple_copy_paste}
    Ghiasi, G., Cui, Y., Srinivas, A., Qian, R., Lin, T.-Y., Cubuk, E. D., Le, Q. V., & Zoph, B. (2021). Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation. In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE. https://doi.org/10.1109/cvpr46437.2021.00294

    \bibitem{sample_code}
    Hu, X., Kocher, A., \& Jiao, Z. (2021). 21LPCVC-UAV\_VIdeo\_Track-Sample-Solution (Version 1.0.0) [Computer software]. Retrieved from \text{https://github.com/lpcvai/21LPCVC-UAV\_VIdeo\_Track-Sample-Solution}


\end{thebibliography}

\keywordalt{Object Tracking, YOLOv5, Deep SORT, Data Augmentation, Dataset Filtering, Merged Data Augmentation}
\begin{abstractalt}
    In this study, we improved the object tracking task to track the person who owns the ball in the video captured by the UAV more accurately. The object tracking module consists of Yolo, which is responsible for object detection, and Deep SORT, which performs multi-object tracking. To alleviate the problem of merged object detection and false positive detection in the object detection module, we trained the object detection model with datasets suitable for the task situation. To construct such a dataset, we introduced and applied dataset filtering and merged data augmentation with Copy-Paste augmentation. This paper includes a definition of the task under study, a brief introduction to the Object Tracking module and Copy-Paste augmentation. In addition, the methodology for dataset filtering and merged data augmentation in this study is described, and the performance of object detection and task performance before and after application is compared and analyzed.

\end{abstractalt}


\end{document}


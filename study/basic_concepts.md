# LLM 환각 탐지 기본 개념

## 1. LLM (Large Language Model)

**LLM = 거대 언어 모델 = 초거대 자동완성 기계**

```
입력: "오늘 날씨가 정말..."
LLM:  "좋네요!" (다음에 올 말을 예측)
```

스마트폰 키보드의 다음 단어 추천 기능을 수십억 배 강화한 것이라고 생각하면 됩니다.

## 2. 토큰 (Token)

LLM은 글자가 아닌 **단어 조각(토큰)** 단위로 생각합니다.

```
"안녕하세요" → ["안녕", "하세요"]     (2개 토큰)
"Hello"     → ["Hello"]            (1개 토큰)
"unhappiness" → ["un", "happiness"] (2개 토큰)
```

## 3. 확률 (Probability)

"얼마나 그럴 것 같은지"를 0~1 사이 숫자로 표현한 것입니다.

```
"프랑스의 수도는 ___"

LLM의 예측:
• "파리" → 95% (0.95)  거의 확실
• "런던" → 2%  (0.02)  
• "피자" → 0.001%      말도 안 됨
```

## 4. 로그 (Log)

큰 숫자를 작게, 작은 숫자를 더 작게 만드는 함수입니다.

```
log(1) = 0
log(10) = 1
log(100) = 2
log(1000) = 3
```

**왜 사용할까?**
- 컴퓨터는 아주 작은 확률(0.0000001)을 다루기 어려움
- 로그를 쓰면 다루기 쉬운 숫자가 됨: log(0.0000001) = -7

**중요한 특징:**
- 확률 1 (100%) → log = 0
- 확률 < 1 → log = 음수
- 확률이 작을수록 → log가 더 큰 음수

## 5. Logit

**Logit = LLM의 "날것의 점수"**

LLM이 다음 단어를 예측할 때, 먼저 각 단어에 점수를 매깁니다:

```
"프랑스의 수도는 ___"

LLM의 날것 점수 (Logit):
• "파리" → 10점
• "런던" → 3점
• "피자" → -5점
```

이 점수는 아무 범위나 가능합니다 (-100 ~ +100 등). **아직 확률이 아닙니다!**

## 6. Softmax

**Logit(점수)을 확률로 바꾸는 함수**

```
입력 (Logit):          출력 (확률):
• "파리" → 10점   →    95%
• "런던" → 3점    →    4%
• "피자" → -5점   →    0.03%
                       ─────
                 합계 = 100%
```

Softmax가 하는 일:
1. 모든 점수를 양수로 만들고
2. 전체 합이 100%가 되게 조정

## 7. Temperature (온도)

**LLM의 "창의성 조절기"**

```
T = 0.1 (차가움): 가장 확률 높은 것만 선택 (보수적)
T = 1.0 (보통):   학습된 대로
T = 2.0 (뜨거움): 다양하게 선택 (창의적/무작위)
```

**비유 - "저녁 뭐 먹을까?"**
- T = 0.1: "밥" (항상 제일 흔한 답)
- T = 1.0: "파스타" (적당히 다양)
- T = 2.0: "악어 스테이크" (엉뚱한 것도 가능)

## 8. NLL (Negative Log Likelihood)

**"이 답변이 얼마나 이상한가"를 측정하는 점수**

```
Step 1: Likelihood(가능도)
"프랑스 수도는?" → "파리"
LLM이 "파리"를 예측할 확률 = 0.95 (95%)

Step 2: Log Likelihood
log(0.95) = -0.05 (거의 0에 가까움 = 좋음!)
log(0.01) = -4.6  (큰 음수 = 이상함!)

Step 3: Negative Log Likelihood (NLL)
앞에 마이너스를 붙여서 양수로 만듦:
NLL = -log(확률)
• 확률 95% → NLL = 0.05 (낮음 = 좋음!)
• 확률 1%  → NLL = 4.6  (높음 = 이상함!)
```

**직관적 이해:** NLL = "놀람의 정도"
- NLL 낮음: "예상했어, 놀랍지 않아" (정상)
- NLL 높음: "헐, 이게 나온다고?" (이상함/환각?)

## 9. 엔트로피 (Entropy)

**"얼마나 불확실한가"를 측정하는 점수**

```
예시 1: 확실한 상황 (낮은 엔트로피)
"1 + 1 = ?"
LLM: "2" (99.9%)
     다른 답 (0.1%)
→ 거의 확실함 → 엔트로피 ≈ 0

예시 2: 불확실한 상황 (높은 엔트로피)
"좋은 영화 추천해줘"
LLM: "인터스텔라" (15%)
     "기생충" (15%)
     "어벤져스" (14%)
     ... 여러 개가 비슷비슷
→ 뭐가 나올지 모름 → 엔트로피 높음
```

**공식:**
```
엔트로피 = -Σ 확률 × log(확률)
```

**직관:**
- 엔트로피 0: "답이 하나야, 확실해"
- 엔트로피 높음: "여러 답이 가능해, 모르겠어"

## 10. 용어 정리표

| 용어 | 설명 |
|------|------|
| **토큰** | LLM이 생각하는 단어 조각 |
| **Logit** | LLM의 날것의 점수 (softmax 전) |
| **Softmax** | 점수를 확률로 바꾸는 함수 |
| **확률** | 0~1 사이, "얼마나 그럴 것 같은지" |
| **Log** | 큰 숫자를 작게 만드는 함수 |
| **NLL** | "이게 얼마나 이상한지" 점수 |
| **엔트로피** | "얼마나 불확실한지" 점수 |
| **환각** | LLM이 자신있게 하는 거짓말 |
| **Semantic Entropy** | 답변들의 의미적 다양성 |
| **Semantic Energy** | Logit 기반 확신도 |
